{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    " \n",
    "'''\n",
    "  - Creates a bounding box around a moving object\n",
    "  - Calculates the coordinates of the centroid of the object\n",
    "  - Tracks the centroid of the object\n",
    " \n",
    "Author:\n",
    "  - Addison Sears-Collins\n",
    "  - https://automaticaddison.com\n",
    "'''\n",
    " \n",
    "from __future__ import print_function # Python 2/3 compatibility\n",
    "import cv2 # Import the OpenCV library\n",
    "import numpy as np # Import Numpy library\n",
    "\n",
    " \n",
    "def main():\n",
    " \n",
    "    # Create a VideoCapture object\n",
    "    cap = cv2.VideoCapture(0)\n",
    " \n",
    "    # Create the background subtractor object\n",
    "    # Use the last 700 video frames to build the background\n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2(history=700, \n",
    "        varThreshold=25, detectShadows=True)\n",
    " \n",
    "    # Create kernel for morphological operation\n",
    "    # You can tweak the dimensions of the kernel\n",
    "    # e.g. instead of 20,20 you can try 30,30.\n",
    "    kernel = np.ones((20,20),np.uint8)\n",
    " \n",
    "    while(True):\n",
    " \n",
    "        # Capture frame-by-frame\n",
    "        # This method returns True/False as well\n",
    "        # as the video frame.\n",
    "        ret, frame = cap.read()\n",
    " \n",
    "        # Use every frame to calculate the foreground mask and update\n",
    "        # the background\n",
    "        fg_mask = back_sub.apply(frame)\n",
    " \n",
    "        # Close dark gaps in foreground object using closing\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    " \n",
    "        # Remove salt and pepper noise with a median filter\n",
    "        fg_mask = cv2.medianBlur(fg_mask, 5) \n",
    "         \n",
    "        # Threshold the image to make it either black or white\n",
    "        _, fg_mask = cv2.threshold(fg_mask,127,255,cv2.THRESH_BINARY)\n",
    " \n",
    "        # Find the index of the largest contour and draw bounding box\n",
    "        fg_mask_bb = fg_mask\n",
    "        contours, hierarchy = cv2.findContours(fg_mask_bb,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "        areas = [cv2.contourArea(c) for c in contours]\n",
    " \n",
    "        # If there are no countours\n",
    "        if len(areas) < 1:\n",
    " \n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('frame',frame)\n",
    " \n",
    "            # If \"q\" is pressed on the keyboard, \n",
    "            # exit this loop\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    " \n",
    "            # Go to the top of the while loop\n",
    "            continue\n",
    " \n",
    "        else:\n",
    "            # Find the largest moving object in the image\n",
    "            max_index = np.argmax(areas)\n",
    " \n",
    "        # Draw the bounding box\n",
    "        cnt = contours[max_index]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    " \n",
    "        # Draw circle in the center of the bounding box\n",
    "        x2 = x + int(w/2)\n",
    "        y2 = y + int(h/2)\n",
    "        cv2.circle(frame,(x2,y2),4,(0,255,0),-1)\n",
    " \n",
    "        # Print the centroid coordinates (we'll use the center of the\n",
    "        # bounding box) on the image\n",
    "        text = \"x: \" + str(x2) + \", y: \" + str(y2)\n",
    "        cv2.putText(frame, text, (x2 - 10, y2 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "         \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame',frame)\n",
    " \n",
    "        # If \"q\" is pressed on the keyboard, \n",
    "        # exit this loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    " \n",
    "    # Close down the video stream\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    print(__doc__)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
